#!/bin/bash
#SBATCH --job-name="zaloAI"
#SBATCH --job-name="FiD"
#SBATCH --output="HAL_outputs/vid.%j.%N.out"
#SBATCH --error="HAL_outputs/vid.%j.%N.err"
#SBATCH --partition=gpux4
#SBATCH --time=24

export MASTER_PORT=12340
export WORLD_SIZE=4
echo "NODELIST="${SLURM_NODELIST}
master_addr=$(scontrol show hostnames "$SLURM_JOB_NODELIST" | head -n 1)
export MASTER_ADDR=$master_addr
echo "MASTER_ADDR="$MASTER_ADDR
module load opence
conda run -n mmpose python -m torch.distributed.launch \
                --nproc_per_node=4 train_reader.py --train_data squad_zalo1.json \
                --eval_data squad_zalo1.json --model_size base --per_gpu_batch_size 10 \
                --n_context 1 --name zaloai
# python -m torch.distributed.launch \
#                 --nproc_per_node=1 train_reader.py --train_data squad_zalo1.json \
#                 --eval_data squad_zalo1.json --model_size base --per_gpu_batch_size 10 \
#                 --n_context 1 --name zaloai